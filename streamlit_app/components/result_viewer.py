"""
ç»“æœæŸ¥çœ‹ç»„ä»¶
"""
import streamlit as st
import pandas as pd
from typing import Any, Dict, List, Optional


# å­—æ®µæ˜¾ç¤ºåç§°æ˜ å°„
FIELD_LABELS = {
    "student_name": "å­¦ç”Ÿå§“å",
    "filename": "æ–‡ä»¶å",
    "final_score": "æœ€ç»ˆåˆ†æ•°",
    "level": "ç”³è¯·å±‚çº§",
    "profile": "ç”³è¯·å½¢è±¡",
    "provider": "è¯„åˆ†æ¨¡å‹",
    "model": "æ¨¡å‹ç‰ˆæœ¬",
    "prompt_name": "Prompt",
    "clearness_and_consistency_score": "æ¸…æ™°ä¸€è‡´æ€§",
    "clearness_and_consistency_evaluation": "æ¸…æ™°ä¸€è‡´æ€§è¯„ä»·",
    "detail_and_executability_score": "è¯¦ç»†å¯æ‰§è¡Œæ€§",
    "detail_and_executability_evaluation": "è¯¦ç»†å¯æ‰§è¡Œæ€§è¯„ä»·",
    "depth_and_intensity_score": "æ·±åº¦å¼ºåº¦",
    "depth_and_intensity_evaluation": "æ·±åº¦å¼ºåº¦è¯„ä»·",
    "noviceness_score": "æ–°é¢–åº¦",
    "noviceness__evaluation": "æ–°é¢–åº¦è¯„ä»·",
    "noviceness_evaluation": "æ–°é¢–åº¦è¯„ä»·",
    "fitness_score": "é€‚é…åº¦",
    "fitness_evaluation": "é€‚é…åº¦è¯„ä»·",
    "liberal_values_score": "ä»·å€¼è§‚",
    "liberal_values_evaluation": "ä»·å€¼è§‚è¯„ä»·",
    "suggestions": "æ”¹è¿›å»ºè®®",
    "thinking": "æ¨¡å‹æ€è€ƒè¿‡ç¨‹",
    "error": "é”™è¯¯ä¿¡æ¯",
}

# åˆ†æ•°å­—æ®µåˆ—è¡¨
SCORE_FIELDS = [
    "clearness_and_consistency_score",
    "detail_and_executability_score",
    "depth_and_intensity_score",
    "noviceness_score",
    "fitness_score",
    "liberal_values_score",
]

# è¯„ä»·å­—æ®µåˆ—è¡¨
EVALUATION_FIELDS = [
    "clearness_and_consistency_evaluation",
    "detail_and_executability_evaluation",
    "depth_and_intensity_evaluation",
    "noviceness__evaluation",
    "noviceness_evaluation",
    "fitness_evaluation",
    "liberal_values_evaluation",
]


def get_field_label(field: str) -> str:
    """è·å–å­—æ®µçš„æ˜¾ç¤ºåç§°"""
    return FIELD_LABELS.get(field, field.replace("_", " ").title())


def display_score_card(result: Dict) -> None:
    """æ˜¾ç¤ºå•ä¸ªè¯„åˆ†å¡ç‰‡"""
    with st.container():
        # æ ‡é¢˜è¡Œ
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            student_name = result.get("student_name", "æœªçŸ¥")
            st.subheader(f"ğŸ‘¤ {student_name}")
        with col2:
            # ä½¿ç”¨ final_score
            score = result.get("final_score", result.get("score", "-"))
            if isinstance(score, (int, float)):
                color = "green" if score >= 80 else "orange" if score >= 60 else "red"
                st.markdown(f"### :{color}[{score}åˆ†]")
            else:
                st.markdown(f"### {score}")
        with col3:
            provider = result.get("provider", "-")
            st.caption(f"ğŸ¤– {provider}")

        # é”™è¯¯ä¿¡æ¯
        if result.get("error"):
            st.error(f"âŒ é”™è¯¯: {result['error']}")
            return

        # è¯¦æƒ…å±•å¼€
        with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦æƒ…"):
            display_result_details(result)


def display_result_details(result: Dict) -> None:
    """æ˜¾ç¤ºç»“æœçš„æ‰€æœ‰è¯¦ç»†å­—æ®µ"""

    # åŸºæœ¬ä¿¡æ¯
    st.markdown("#### ğŸ“Œ åŸºæœ¬ä¿¡æ¯")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"**å­¦ç”Ÿå§“å:** {result.get('student_name', '-')}")
    with col2:
        st.markdown(f"**æœ€ç»ˆåˆ†æ•°:** {result.get('final_score', result.get('score', '-'))}")
    with col3:
        st.markdown(f"**ç”³è¯·å±‚çº§:** {result.get('level', '-')}")

    # ç”³è¯·å½¢è±¡
    if result.get("profile"):
        st.markdown("#### ğŸ­ ç”³è¯·å½¢è±¡")
        st.info(result["profile"])

    # å­ç»´åº¦åˆ†æ•°
    st.markdown("#### ğŸ“Š å„ç»´åº¦è¯„åˆ†")
    score_cols = st.columns(3)
    score_items = [
        ("clearness_and_consistency_score", "æ¸…æ™°ä¸€è‡´æ€§"),
        ("detail_and_executability_score", "è¯¦ç»†å¯æ‰§è¡Œæ€§"),
        ("depth_and_intensity_score", "æ·±åº¦å¼ºåº¦"),
        ("noviceness_score", "æ–°é¢–åº¦"),
        ("fitness_score", "é€‚é…åº¦"),
        ("liberal_values_score", "ä»·å€¼è§‚"),
    ]

    for i, (key, label) in enumerate(score_items):
        if key in result:
            with score_cols[i % 3]:
                score = result[key]
                color = "ğŸŸ¢" if score >= 80 else "ğŸŸ¡" if score >= 60 else "ğŸ”´"
                st.metric(f"{color} {label}", f"{score}åˆ†")

    # å„ç»´åº¦è¯¦ç»†è¯„ä»·
    st.markdown("#### ğŸ“ å„ç»´åº¦è¯„ä»·")

    eval_items = [
        ("clearness_and_consistency_evaluation", "æ¸…æ™°ä¸€è‡´æ€§è¯„ä»·"),
        ("detail_and_executability_evaluation", "è¯¦ç»†å¯æ‰§è¡Œæ€§è¯„ä»·"),
        ("depth_and_intensity_evaluation", "æ·±åº¦å¼ºåº¦è¯„ä»·"),
        ("noviceness__evaluation", "æ–°é¢–åº¦è¯„ä»·"),
        ("noviceness_evaluation", "æ–°é¢–åº¦è¯„ä»·"),
        ("fitness_evaluation", "é€‚é…åº¦è¯„ä»·"),
        ("liberal_values_evaluation", "ä»·å€¼è§‚è¯„ä»·"),
    ]

    for key, label in eval_items:
        if key in result and result[key]:
            with st.expander(f"ğŸ“„ {label}"):
                st.write(result[key])

    # æ”¹è¿›å»ºè®®
    if result.get("suggestions"):
        st.markdown("#### ğŸ’¡ æ”¹è¿›å»ºè®®")
        suggestions = result["suggestions"]
        if isinstance(suggestions, list):
            for i, s in enumerate(suggestions, 1):
                st.markdown(f"{i}. {s}")
        else:
            st.write(suggestions)

    # æ¨¡å‹æ€è€ƒè¿‡ç¨‹
    if result.get("thinking"):
        with st.expander("ğŸ§  æ¨¡å‹æ€è€ƒè¿‡ç¨‹"):
            st.text_area(
                "Thinking",
                value=result["thinking"],
                height=300,
                disabled=True,
                label_visibility="collapsed"
            )

    # å…ƒä¿¡æ¯
    st.markdown("#### âš™ï¸ è¯„åˆ†å…ƒä¿¡æ¯")
    meta_col1, meta_col2, meta_col3 = st.columns(3)
    with meta_col1:
        st.caption(f"æ¨¡å‹: {result.get('provider', '-')}")
    with meta_col2:
        st.caption(f"ç‰ˆæœ¬: {result.get('model', '-')}")
    with meta_col3:
        st.caption(f"Prompt: {result.get('prompt_name', '-')}")

    # æ˜¾ç¤ºå…¶ä»–æœªåˆ—å‡ºçš„å­—æ®µ
    displayed_keys = {
        "student_name", "filename", "final_score", "score", "level", "profile",
        "provider", "model", "prompt_name", "suggestions", "thinking", "error",
        *[k for k, _ in score_items],
        *[k for k, _ in eval_items],
    }

    other_fields = {k: v for k, v in result.items() if k not in displayed_keys and v}

    if other_fields:
        st.markdown("#### ğŸ“ å…¶ä»–å­—æ®µ")
        for key, value in other_fields.items():
            label = get_field_label(key)
            if isinstance(value, (str, int, float)):
                st.markdown(f"**{label}:** {value}")
            elif isinstance(value, list):
                st.markdown(f"**{label}:**")
                for item in value:
                    st.markdown(f"  - {item}")


def display_results_table(results: List[Dict], key: str = "results_table") -> Optional[Dict]:
    """
    æ˜¾ç¤ºç»“æœè¡¨æ ¼

    Returns:
        é€‰ä¸­çš„è¡Œï¼ˆå¦‚æœæœ‰ï¼‰
    """
    if not results:
        st.info("æš‚æ— è¯„åˆ†ç»“æœ")
        return None

    # å‡†å¤‡æ•°æ® - ä½¿ç”¨ final_score
    df_data = []
    for r in results:
        df_data.append({
            "å­¦ç”Ÿå§“å": r.get("student_name", "-"),
            "æœ€ç»ˆåˆ†æ•°": r.get("final_score", r.get("score", "-")),
            "ç”³è¯·å±‚çº§": r.get("level", "-"),
            "æ¨¡å‹": r.get("provider", "-"),
            "Prompt": r.get("prompt_name", "-"),
            "çŠ¶æ€": "âœ…" if not r.get("error") else "âŒ",
        })

    df = pd.DataFrame(df_data)

    # æ˜¾ç¤ºè¡¨æ ¼
    st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "æœ€ç»ˆåˆ†æ•°": st.column_config.NumberColumn(format="%d"),
        }
    )

    return None


def display_score_distribution(results: List[Dict]) -> None:
    """æ˜¾ç¤ºåˆ†æ•°åˆ†å¸ƒå›¾"""
    # ä½¿ç”¨ final_score
    scores = [r.get("final_score", r.get("score")) for r in results
              if r.get("final_score") is not None or r.get("score") is not None]

    if not scores:
        st.info("æš‚æ— æœ‰æ•ˆåˆ†æ•°æ•°æ®")
        return

    df = pd.DataFrame({"åˆ†æ•°": scores})
    st.bar_chart(df["åˆ†æ•°"].value_counts().sort_index())


def display_summary_metrics(results: List[Dict]) -> None:
    """æ˜¾ç¤ºæ±‡æ€»æŒ‡æ ‡"""
    if not results:
        return

    success = [r for r in results if not r.get("error")]
    errors = [r for r in results if r.get("error")]
    # ä½¿ç”¨ final_score
    scores = [r.get("final_score", r.get("score")) for r in success
              if r.get("final_score") is not None or r.get("score") is not None]

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ€»æ•°", len(results))

    with col2:
        st.metric("æˆåŠŸ", len(success), delta=None)

    with col3:
        if errors:
            st.metric("å¤±è´¥", len(errors), delta=None)
        else:
            st.metric("å¤±è´¥", 0)

    with col4:
        if scores:
            avg = sum(scores) / len(scores)
            st.metric("å¹³å‡åˆ†", f"{avg:.1f}")
        else:
            st.metric("å¹³å‡åˆ†", "-")
